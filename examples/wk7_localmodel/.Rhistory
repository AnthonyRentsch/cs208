plot(values, type="h", lwd=3)
showHistLocal <- function(DPrelease, true, codebook, main="Histogram"){
semi.blue <- rgb(0,90,239,150,maxColorValue=255)          # Slightly transparent colors
semi.red  <- rgb(239,90,0,150,maxColorValue=255)
allylim <- c(min(c(DPrelease,true), na.rm = TRUE), max(c(DPrelease, true), na.rm = TRUE))
granularity <- (max(codebook) - min(codebook))/(length(codebook)-1)
allxlim <- c(min(codebook) - 0.5*granularity, max(codebook + 0.5*granularity))
# Build empty plot
plot.new()
plot.window( xlim=allxlim, ylim=allylim)
title(main = main)
axis( side=1 )
axis( side=2 )
tiny <- granularity*0.03 # slight spacing between bars
overlap <- granularity*0.2 # some small overlap between sensitive and DP values
for(i in 1:length(codebook)){
rect(xleft=codebook[i]-overlap, ybottom=0, xright=codebook[i]+0.5*granularity-tiny, ytop=true[i], col=semi.red)
rect(xleft=codebook[i]-0.5*granularity+tiny, ybottom=0, xright=codebook[i]+overlap, ytop=DPrelease[i], col=semi.blue)
}
}
values <- apply(out1,2,mean)
DPmeans <- correction01(values, epsilon=0.5)
true <- truefrac(data1, lower=1, upper=16)
par(mfcol=c(1,1))
showHistLocal(DPrelease=DPmeans, true=true, codebook=1:16, main="Histogram of Local Model Release of Education")
dev.copy2pdf(file="./figs/localEducHist.pdf")
values <- apply(out1,2,mean)
DPmeans <- correction01(values, epsilon=0.5, sensitivity=2)
true <- truefrac(data1, lower=1, upper=16)
par(mfcol=c(1,1))
showHistLocal(DPrelease=DPmeans, true=true, codebook=1:16, main="Histogram of Local Model Release of Education")
dev.copy2pdf(file="./figs/localEducHist.pdf")
library("openssl")
sha256(c("james","salil","james"), key="my_secret")
letters
thash <- function(x){
x <- tolower(x)
hash<-NULL
for(i in 1:length(x)){
first.letter <- substr(x[i], start=1, stop=1)
temp <- which(first.letter==letters)
hash <- c(hash, max(temp,0))         # max helps map nonletters to 0
}
return(hash)
}
thash2 <- function(x){
x <- tolower(x)
hash<-NULL
for(i in 1:length(x)){
last.letter <- substr(x[i], start=nchar(x[i]), stop=nchar(x[i]))
temp <- which(last.letter==letters)
hash <- c(hash, max(temp,0))         # max helps map nonletters to 0
}
return(hash)
}
data("iris")
iris
names <- bootstrap(iris$Species, n=5000)
names.hash <- thash(names)
names.hash
names
clientSFP <- function(x, epsilon, myhash){
a <- localHistogramRelease(x=myhash(x), lower=0, upper=26, epsilon=epsilon)
l <- ceiling(runif(1, min=0, max=10))
b <- substr(x, start=l, stop=l)
return(list(a=a, b=b, l=l))
}
x <- bootstrap(iris$Species, n=10000)
l <- rep(1,length(x))
b <- rep("a",length(x))
out4 <- matrix(NA, nrow=length(x), ncol=27)
myepsilon <- 2
for(i in 1:length(x)){
release <- clientSFP(x[i], epsilon=myepsilon, myhash=thash)
out4[i,] <- release$a
b[i] <- release$b
l[i] <- release$l
}
release
release$a
clientSFP <- function(x, epsilon, myhash){
a <- localHistogramRelease(x=myhash(x), lower=0, upper=26, epsilon=epsilon)$release
l <- ceiling(runif(1, min=0, max=10))
b <- substr(x, start=l, stop=l)
return(list(a=a, b=b, l=l))
}
x <- bootstrap(iris$Species, n=10000)
l <- rep(1,length(x))
b <- rep("a",length(x))
out4 <- matrix(NA, nrow=length(x), ncol=27)
myepsilon <- 2
for(i in 1:length(x)){
release <- clientSFP(x[i], epsilon=myepsilon, myhash=thash)
out4[i,] <- release$a
b[i] <- release$b
l[i] <- release$l
}
codebook <- 0:26
values <- apply(out4,2,mean)
DPmeans <- correction01(values, epsilon=myepsilon, sensitivity=2)
true <- truefrac(thash(x), lower=0, upper=26)
showHistLocal(DPrelease=DPmeans, true=true, codebook=0:27, main="Histogram of Local Model Release of Name Hash")
dev.copy2pdf(file="./figs/localHashHist.pdf")
Threshold <- 0.1
discovered <- which(DPmeans>Threshold)
cat("Actual Names: \n")
cat(paste(sort(unique(iris$Species)), "\n"))
for(j in 1:length(discovered)){
flag <- out4[,discovered[j]] == 1
temp.b <- b[flag]
temp.l <- l[flag]
t <- table(temp.b,temp.l)
print(t)
size <- ncol(t)
word <- rep("",size)
for(k in 1:ncol(t)){
word[k]<-row.names(t)[which(t[,k]==max(t[,k]))][1]
}
print(word)
}
x <- bootstrap(iris$Species, n=10000)
l <- rep(1,length(x))
b <- rep("a",length(x))
out4 <- matrix(NA, nrow=length(x), ncol=27)
myepsilon <- 2
for(i in 1:length(x)){
release <- clientSFP(x[i], epsilon=myepsilon, myhash=thash2)
out4[i,] <- release$a
b[i] <- release$b
l[i] <- release$l
}
codebook <- 0:26
values <- apply(out4,2,mean)
DPmeans <- correction01(values, epsilon=myepsilon, sensitivity=2)
true <- truefrac(thash(x), lower=0, upper=26)
showHistLocal(DPrelease=DPmeans, true=true, codebook=0:27, main="Histogram of Local Model Release of Name Hash")
codebook <- 0:26
values <- apply(out4,2,mean)
DPmeans <- correction01(values, epsilon=myepsilon, sensitivity=2)
true <- truefrac(thash2(x), lower=0, upper=26)
showHistLocal(DPrelease=DPmeans, true=true, codebook=0:27, main="Histogram of Local Model Release of Name Hash")
dev.copy2pdf(file="./figs/localHashHist.pdf")
Threshold <- 0.1
discovered <- which(DPmeans>Threshold)
cat("Actual Names: \n")
cat(paste(sort(unique(iris$Species)), "\n"))
for(j in 1:length(discovered)){
flag <- out4[,discovered[j]] == 1
temp.b <- b[flag]
temp.l <- l[flag]
t <- table(temp.b,temp.l)
print(t)
size <- ncol(t)
word <- rep("",size)
for(k in 1:ncol(t)){
word[k]<-row.names(t)[which(t[,k]==max(t[,k]))][1]
}
print(word)
}
library.list <- c("glmnet", "limSolve", "ggplot2", "optparse", "shiny")
install.packages(library.list, repos="https://cran.cnr.berkeley.edu/")
calcllik<-function(b,data){
y<-data[,1]
x<-data[,2]
pi<- 1/(1+exp(-b[1] - b[2]*x))        # Here is the systematic component
llik<-y * log(pi) + (1-y) * log(1-pi) # Here is the stocastic component
return(-llik)
}
gaussianReleaseNoise <- function(size=1, sensitivity, epsilon, delta){
scale <- sensitivity *log(1.25/delta)/ epsilon
noise <- rnorm(n=size, mean=0, sd=scale)
return(noise)
}
clip <- function(x, lower, upper){
x.clipped <- x
x.clipped[x.clipped<lower] <- lower
x.clipped[x.clipped>upper] <- upper
return(x.clipped)
}
library("foreign")
PUMSdata <- read.csv(file="../../data/MaPUMS5full.csv")
mydata<-PUMSdata[c("married","educ")]
output <- glm(married ~ educ, family="binomial", data=mydata)
print(summary(output))
getwd()
xseq <- seq(from=-40, to=60, length=100)
f <- 1/(1 + exp(-output$coef[1] -output$coef[2]*xseq))
par(mfcol=c(2,1))
plot(xseq, f, type="l", lwd=1.5, col="red", ylim=c(0,1), ylab="E(y|x,theta)", xlab="education", main="Probability Married by Education")
abline(v=1, col="blue", lty=3)
abline(v=16, col="blue", lty=3)
plot(xseq, f, type="l", lwd=1.5, col="red", ylim=c(0,1), ylab="E(y|x,theta)", xlab="education", xlim=c(-5,20))
for(i in 1:16){
flag<-mydata$educ==i
points(x=i, y=mean(mydata[flag,"married"]))
}
dev.copy2pdf(file="./figs/married_educ.pdf")
sample.data <- mydata[sample(1:nrow(mydata),10000), ]
b1.seq <- seq(from=-3, to=2, length=25)
b2.seq <- seq(from=-.2, to=.3, length=25)
llsurface <- matrix(NA, nrow=length(b1.seq), ncol=length(b2.seq))
for(i in 1:length(b1.seq)){
for(j in 1:length(b2.seq)){
llsurface[i,j] <- sum(-1* calcllik(b=c(b1.seq[i], b2.seq[j]), data=sample.data) )
}
}
filled.contour(x=b1.seq, y=b2.seq, z=llsurface, color = terrain.colors,  xlab="constant parameter", ylab="education parameter")
dev.copy2pdf(file="./figs/logitLLike.pdf")
calcgradient <- function(B, C, theta, fun){
dx <- 0.0001
out1 <-	eval(fun(b=theta, data=B))
out2 <- eval(fun(b=theta + c(0,dx), data=B))
out3 <- eval(fun(b=theta + c(dx,0), data=B))
Del.1 <- 1
# Del.1 <- clip(Del.1, lower=0, upper=1)  # Fix this
mean.Del.1 <- mean(Del.1)
Del.2 <- 1
# Del.2 <- clip(Del.2, lower=0, upper=1)  # Fix this
mean.Del.2 <- mean(Del.2)
return(c(mean.Del.1,mean.Del.2))
}
calcgradient <- function(B, C, theta, fun){
dx <- 0.0001
out1 <-	eval(fun(b=theta, data=B))
out2 <- eval(fun(b=theta + c(0,dx), data=B))
out3 <- eval(fun(b=theta + c(dx,0), data=B))
Del.1 <- (out2-out1)/dx
# Del.1 <- clip(Del.1, lower=0, upper=1)  # Fix this
mean.Del.1 <- mean(Del.1)
Del.2 <- (out3-out1)/dx
# Del.2 <- clip(Del.2, lower=0, upper=1)  # Fix this
mean.Del.2 <- mean(Del.2)
return(c(mean.Del.1,mean.Del.2))
}
N <- nrow(mydata)
L <- round(sqrt(nrow(mydata)))
steps <- 100   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik)
cat("Del:  ",Del,"\n")
theta <- theta   				# Fix this
cat("Theta:",theta, "\n")
history[i+1,] <- theta
}
par(mfcol=c(2,1))
all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))
plot(history[,1], type="l", ylim=all.ylim, ylab="beta 0", xlab="step", lwd=1.5)
abline(h=output$coef[1], lty=2, col="blue", lwd=1.5)
all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))
plot(history[,2], type="l", ylim=all.ylim, ylab="beta 1", xlab="step", lwd=1.5)
abline(h=output$coef[2], lty=2, col="blue", lwd=1.5)
dev.copy2pdf(file="./figs/dpSGD.pdf")
calcgradient <- function(B, C, theta, fun){
dx <- 0.0001
out1 <-	eval(fun(b=theta, data=B))
out2 <- eval(fun(b=theta + c(0,dx), data=B))
out3 <- eval(fun(b=theta + c(dx,0), data=B))
Del.1 <- (out3-out1)/dx
# Del.1 <- clip(Del.1, lower=0, upper=1)  # Fix this
mean.Del.1 <- mean(Del.1)
Del.2 <- (out2-out1)/dx
# Del.2 <- clip(Del.2, lower=0, upper=1)  # Fix this
mean.Del.2 <- mean(Del.2)
return(c(mean.Del.1,mean.Del.2))
}
N <- nrow(mydata)
L <- round(sqrt(nrow(mydata)))
steps <- 100   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik)
cat("Del:  ",Del,"\n")
theta <- theta   				# Fix this
cat("Theta:",theta, "\n")
history[i+1,] <- theta
}
par(mfcol=c(2,1))
all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))
plot(history[,1], type="l", ylim=all.ylim, ylab="beta 0", xlab="step", lwd=1.5)
abline(h=output$coef[1], lty=2, col="blue", lwd=1.5)
all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))
plot(history[,2], type="l", ylim=all.ylim, ylab="beta 1", xlab="step", lwd=1.5)
abline(h=output$coef[2], lty=2, col="blue", lwd=1.5)
dev.copy2pdf(file="./figs/dpSGD.pdf")
calcgradient <- function(B, C, theta, fun){
dx <- 0.0001
out1 <-	eval(fun(b=theta, data=B))
out2 <- eval(fun(b=theta + c(0,dx), data=B))
out3 <- eval(fun(b=theta + c(dx,0), data=B))
Del.1 <- (out3-out1)/dx
# Del.1 <- clip(Del.1, lower=0, upper=1)  # Fix this
mean.Del.1 <- mean(Del.1)
Del.2 <- (out2-out1)/dx
# Del.2 <- clip(Del.2, lower=0, upper=1)  # Fix this
mean.Del.2 <- mean(Del.2)
return(c(mean.Del.1,mean.Del.2))
}
N <- nrow(mydata)
L <- round(sqrt(nrow(mydata)))
steps <- 100   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik)
cat("Del:  ",Del,"\n")
theta <- theta - Del*nu  				# Fix this
cat("Theta:",theta, "\n")
history[i+1,] <- theta
}
par(mfcol=c(2,1))
all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))
plot(history[,1], type="l", ylim=all.ylim, ylab="beta 0", xlab="step", lwd=1.5)
abline(h=output$coef[1], lty=2, col="blue", lwd=1.5)
all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))
plot(history[,2], type="l", ylim=all.ylim, ylab="beta 1", xlab="step", lwd=1.5)
abline(h=output$coef[2], lty=2, col="blue", lwd=1.5)
dev.copy2pdf(file="./figs/dpSGD.pdf")
steps <- 200   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik)
#cat("Del:  ",Del,"\n")
theta <- theta - Del*nu  				# Fix this
#cat("Theta:",theta, "\n")
history[i+1,] <- theta
}
par(mfcol=c(2,1))
all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))
plot(history[,1], type="l", ylim=all.ylim, ylab="beta 0", xlab="step", lwd=1.5)
abline(h=output$coef[1], lty=2, col="blue", lwd=1.5)
all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))
plot(history[,2], type="l", ylim=all.ylim, ylab="beta 1", xlab="step", lwd=1.5)
abline(h=output$coef[2], lty=2, col="blue", lwd=1.5)
dev.copy2pdf(file="./figs/dpSGD.pdf")
steps <- 1000   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik)
#cat("Del:  ",Del,"\n")
theta <- theta - Del*nu  				# Fix this
#cat("Theta:",theta, "\n")
history[i+1,] <- theta
}
steps <- L   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik)
#cat("Del:  ",Del,"\n")
theta <- theta - Del*nu  				# Fix this
#cat("Theta:",theta, "\n")
history[i+1,] <- theta
}
par(mfcol=c(2,1))
all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))
plot(history[,1], type="l", ylim=all.ylim, ylab="beta 0", xlab="step", lwd=1.5)
abline(h=output$coef[1], lty=2, col="blue", lwd=1.5)
all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))
plot(history[,2], type="l", ylim=all.ylim, ylab="beta 1", xlab="step", lwd=1.5)
abline(h=output$coef[2], lty=2, col="blue", lwd=1.5)
dev.copy2pdf(file="./figs/dpSGD.pdf")
calcgradient <- function(B, C, theta, fun){
dx <- 0.0001
out1 <-	eval(fun(b=theta, data=B))
out2 <- eval(fun(b=theta + c(0,dx), data=B))
out3 <- eval(fun(b=theta + c(dx,0), data=B))
Del.1 <- (out3-out1)/dx
Del.1 <- clip(Del.1, lower=-C, upper=C)
mean.Del.1 <- mean(Del.1)
Del.2 <- (out2-out1)/dx
Del.2 <- clip(Del.2, lower=-C, upper=C)
mean.Del.2 <- mean(Del.2)
return(c(mean.Del.1,mean.Del.2))
}
calcgradient <- function(B, C, theta, fun){
dx <- 0.0001
out1 <-	eval(fun(b=theta, data=B))
out2 <- eval(fun(b=theta + c(0,dx), data=B))
out3 <- eval(fun(b=theta + c(dx,0), data=B))
Del.1 <- (out3-out1)/dx
Del.1 <- clip(Del.1, lower=-C, upper=C)
mean.Del.1 <- mean(Del.1)
Del.2 <- (out2-out1)/dx
Del.2 <- clip(Del.2, lower=-C, upper=C)
mean.Del.2 <- mean(Del.2)
return(c(mean.Del.1,mean.Del.2))
}
N <- nrow(mydata)
L <- round(sqrt(nrow(mydata)))
steps <- L   	  # Fix this
index <- sample(1:nrow(mydata))
mydata <- mydata[index,]
epsilon <-1
delta <- 1e-5
theta <- c(0,0)   # Starting parameters
C <- 10			  # Interval to clip over
nu <- c(1,0.01)   # Learning speeds
history <- matrix(NA, nrow=steps+1, ncol=2)
history[1,] <- theta
for(i in 1:steps){
startB <- ((i-1)*L+1)
if(i<L){
stopB <- i*L
}else{
stopB <- nrow(mydata)
}
index<-sample(1:nrow(mydata),L)
B <- mydata[startB:stopB, ]
Del <- calcgradient(B, C, theta, fun=calcllik) + gaussianReleaseNoise(size=2, sensitivity=2*C/L, epsilon=epsilon*L/2, delta=delta)
# multiply epsilon by L because there is a chance that an observation isn't in the batch
# so we can use a higher epsilon while paying, in expectation, same privacy price
# split up epsilon by 2 because we
theta <- theta - Del*nu
history[i+1,] <- theta
}
par(mfcol=c(2,1))
all.ylim<-c( min(c(history[,1],output$coef[1] )), max(c(history[,1],output$coef[1] )))
plot(history[,1], type="l", ylim=all.ylim, ylab="beta 0", xlab="step", lwd=1.5)
abline(h=output$coef[1], lty=2, col="blue", lwd=1.5)
all.ylim<-c( min(c(history[,2],output$coef[2] )), max(c(history[,2],output$coef[2] )))
plot(history[,2], type="l", ylim=all.ylim, ylab="beta 1", xlab="step", lwd=1.5)
abline(h=output$coef[2], lty=2, col="blue", lwd=1.5)
dev.copy2pdf(file="./figs/dpSGD.pdf")
