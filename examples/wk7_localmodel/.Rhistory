true <- mean(mydata)
release <- rep(NA, myn)
for(i in 1:myn){
release[i] <- localRelease(x=mydata[i], values=c(-1,1), epsilon=myepsilon)
}
expectation <- correction(release=release, epsilon=myepsilon)
startparams <- -1
output <- nlm(p=startparams, f=llik, data=release, epsilon=myepsilon, stepmax=0.1)
maxlik.p <- 1/(1+exp(-1* output$estimate))
maxlik.mean <- maxlik.p * max(mydata) + (1-maxlik.p) * min(mydata)
cat(paste("Mean of data:       ", mean(mydata), "\n"))
cat(paste("Mean of DP release: ", mean(release), "\n"))
cat(paste("Mean corrected:     ", expectation, "\n"))
cat(paste("MaxLikelihood mean: ", maxlik.mean, "\n"))
myn <- 1000
myepsilon <- 0.5
# Simulate dataset
mydata<-rbinom(n=myn, size=1, prob=0.3)
mydata[mydata==0] <- -1
true <- mean(mydata)
# Release each observation by RR
release <- rep(NA, myn)
for(i in 1:myn){
release[i] <- localRelease(x=mydata[i], values=c(-1,1), epsilon=myepsilon)
}
# Correct expectation by inflation
expectation <- correction(release=release, epsilon=myepsilon)
# Correct expectation by Max.Likelihood
startparams <- -1
#output <- optim(par=startparams, fn=llik, data=mydata, epsilon=myepsilon, method="BFGS")  # Alt optimizer
output <- nlm(p=startparams, f=llik, data=release, epsilon=myepsilon, stepmax=0.1)
maxlik.p <- 1/(1+exp(-1* output$estimate))
maxlik.mean <- maxlik.p * max(mydata) + (1-maxlik.p) * min(mydata)
cat(paste("Mean of data:       ", mean(mydata), "\n"))
cat(paste("Mean of DP release: ", mean(release), "\n"))
cat(paste("Mean corrected:     ", expectation, "\n"))
cat(paste("MaxLikelihood mean: ", maxlik.mean, "\n"))
lik <- function(b, data, epsilon){
p <- 1/(1 + exp(-b))             	# Transform unconstrained b into 0<p<1
values <- sort(unique(data))        # Transform dichotomous data into z \in {0,1}
z <- rep(0, length(data))
z[data==values[2]] <- 1
ptrue <- exp(epsilon)/(1+exp(epsilon))
pfalse <- 1 - ptrue  # Or 1/(1-exp(epsilon))
# Here's the likelihood function
lik <- -1*( p * ptrue + (1-p) * pfalse)^(sum(z)) * ((1-p) * ptrue + p * pfalse)^(sum(1-z))
return(lik)
}
p.seq <- seq(from=.01, to=.99, by=.001)     # These are the probabilities we want to find the llikelihood of
b.seq <- -log(p.seq^{-1} - 1)              # These are the inverse transformations
y.lik <- y.llik <- rep(NA, length(p.seq))
for(i in 1:length(p.seq)){
y.llik[i] <- -1*llik(b=b.seq[i], data=release, epsilon=myepsilon)
y.lik[i] <- -1*lik(b=b.seq[i], data=release, epsilon=myepsilon)
}
par(mfcol=c(2,1))
plot(x=p.seq, y=y.llik, type="l", lwd=2, main="LogLikelihood Surface", xlab="Pi Parameter", ylab="LogLikelihood")
plot(x=p.seq, y=y.lik, type="l", lwd=2, main="Likelihood Surface", xlab="Pi Parameter", ylab="Likelihood")
dev.copy2pdf(file="./figs/localModelLLikelihood.pdf")
rm(list=ls())		# Remove any objects in memory
set.seed(123)
localRelease <- function(x, values=c(-1,1), epsilon){
draw <- runif(n=1, min=0, max=1)
cutoff <- 1/(1+exp(epsilon))
return_val <- ifelse(draw < cutoff, !values %in% x, x)
return(return_val)
}
correction <- function(release, epsilon){
inflation <- (exp(epsilon) + 1)/(exp(epsilon) - 1)
expectation <- mean(release * inflation)
return(expectation)
}
llik <- function(b, data, epsilon){
p <- 1/(1 + exp(-b))             	# Transform unconstrained b into 0<p<1
values <- sort(unique(data))        # Transform dichotomous data into z \in {0,1}
z <- rep(0, length(data))
z[data==values[2]] <- 1
ptrue <- exp(epsilon)/(1+exp(epsilon))
pfalse <- 1 - ptrue  # Or 1/(1-exp(epsilon))
# Here's the log likelihood function as a row by row calculation
llik <- sum(z)*log(p*ptrue + (1-p)*pfalse) + sum((1-z))*log((1-p)*ptrue + p*pfalse)
llik <- -1 * llik  			# Note optim performs minimization
return(llik)
}
lik <- function(b, data, epsilon){
p <- 1/(1 + exp(-b))             	# Transform unconstrained b into 0<p<1
values <- sort(unique(data))        # Transform dichotomous data into z \in {0,1}
z <- rep(0, length(data))
z[data==values[2]] <- 1
ptrue <- exp(epsilon)/(1+exp(epsilon))
pfalse <- 1 - ptrue  # Or 1/(1-exp(epsilon))
# Here's the likelihood function
lik <- -1*( p * ptrue + (1-p) * pfalse)^(sum(z)) * ((1-p) * ptrue + p * pfalse)^(sum(1-z))
return(lik)
}
rlap = function(mu=0, b=1, size=1) {
p <- runif(size) - 0.5
draws <- mu - b * sgn(p) * log(1 - 2 * abs(p))
return(draws)
}
sgn <- function(x) {
return(ifelse(x < 0, -1, 1))
}
clip <- function(x, lower, upper){
x.clipped <- x
x.clipped[x.clipped<lower] <- lower
x.clipped[x.clipped>upper] <- upper
return(x.clipped)
}
meanRelease <- function(x, lower, upper, epsilon){
n <- length(x)
sensitivity <- (upper - lower)/n
scale <- sensitivity / epsilon
x.clipped <- clip(x, lower, upper)
sensitiveValue <- mean(x.clipped)
DPrelease <- sensitiveValue + rlap(mu=0, b=scale, size=1)
return(list(release=DPrelease, true=sensitiveValue))
}
my.seq <- seq(from=log10(10), to=log10(0.01), length=50)     	# make evenly spaced in logarithmic space
ep.seq <- round(10^my.seq * 100) /100
probtrue <- exp(ep.seq)/(1 + exp(ep.seq))
par(mfcol=c(1,1))
plot(x=ep.seq, y=probtrue, type="l", log = "x", lwd=2, main="Probability Truth in Randomized Response", xlab="epsilon", ylab="probability")
myn <- 1000
myepsilon <- 0.5
mydata<-rbinom(n=myn, size=1, prob=0.3)
mydata[mydata==0] <- -1
true <- mean(mydata)
release <- rep(NA, myn)
for(i in 1:myn){
release[i] <- localRelease(x=mydata[i], values=c(-1,1), epsilon=myepsilon)
}
expectation <- correction(release=release, epsilon=myepsilon)
startparams <- -1
output <- nlm(p=startparams, f=llik, data=release, epsilon=myepsilon, stepmax=0.1)
maxlik.p <- 1/(1+exp(-1* output$estimate))
maxlik.mean <- maxlik.p * max(mydata) + (1-maxlik.p) * min(mydata)
cat(paste("Mean of data:       ", mean(mydata), "\n"))
cat(paste("Mean of DP release: ", mean(release), "\n"))
cat(paste("Mean corrected:     ", expectation, "\n"))
cat(paste("MaxLikelihood mean: ", maxlik.mean, "\n"))
p.seq <- seq(from=.01, to=.99, by=.001)     # These are the probabilities we want to find the llikelihood of
b.seq <- -log(p.seq^{-1} - 1)              # These are the inverse transformations
y.lik <- y.llik <- rep(NA, length(p.seq))
for(i in 1:length(p.seq)){
y.llik[i] <- -1*llik(b=b.seq[i], data=release, epsilon=myepsilon)
y.lik[i] <- -1*lik(b=b.seq[i], data=release, epsilon=myepsilon)
}
par(mfcol=c(2,1))
plot(x=p.seq, y=y.llik, type="l", lwd=2, main="LogLikelihood Surface", xlab="Pi Parameter", ylab="LogLikelihood")
plot(x=p.seq, y=y.lik, type="l", lwd=2, main="Likelihood Surface", xlab="Pi Parameter", ylab="Likelihood")
all.ylim <- c(min(y.llik), 1.2*max(y.llik)  - 0.2*min(y.llik))
plot(x=p.seq, y=y.llik, type="l", lwd=2, main="LogLikelihood Surface with Likelihood Ratio Test", ylim=all.ylim, xlab="Pi Parameter", ylab="LogLikelihood")
test.statistic=max(y.llik) - qchisq(0.95, df=1)/2
abline(h=test.statistic,lty=4)
myn <- 5000
myepsilon <- 0.5
mydata<-rbinom(n=myn, size=1, prob=0.3)
mydata[mydata==0] <- -1
true <- mean(mydata)
nsims <- 500
history <- matrix(NA, nrow=nsims, ncol=4)
release <- rep(NA, myn)
for(j in 1:nsims){
for(i in 1:myn){
release[i] <- localRelease(x=mydata[i], values=c(-1,1), epsilon=myepsilon)
}
expectation <- correction(release=release, epsilon=myepsilon)
startparams <- -1
output <- nlm(p=startparams, f=llik, data=release, epsilon=myepsilon, stepmax=0.1)
maxlik.p <- 1/(1+exp(-1* output$estimate))
maxlik.mean <- maxlik.p * max(mydata) + (1-maxlik.p) * min(mydata)
laplace.release <- meanRelease(x=mydata, lower=-1, upper=1, epsilon=myepsilon)
history[j,1] <- mean(release)
history[j,2] <- expectation
history[j,3] <- maxlik.mean
history[j,4] <- laplace.release$release
}
dens.release <- density(history[,1])
dens.exp <- density(history[,2])
dens.maxlik <- density(history[,3])
dens.laplace <- density(history[,4])
all.ylim <- c(min(c(dens.release$y, dens.exp$y, dens.maxlik$y)), max(c(dens.release$y, dens.exp$y, dens.maxlik$y)))
all.xlim <- c(min(c(true, dens.release$x, dens.exp$x, dens.maxlik$x)), max(c(true, dens.release$x, dens.exp$x, dens.maxlik$x)))
all.lwd <- 2
col.seq <- c("coral3", "darkolivegreen3", "cornflowerblue", "violet")
plot(x=dens.release$x, y=dens.release$y, type="l", lwd=all.lwd, col=col.seq[1],  ylim=all.ylim, xlim=all.xlim, xlab="release", ylab="density")
lines(x=dens.exp$x, y=dens.exp$y, type="l", lwd=all.lwd, col=col.seq[3])
lines(x=dens.maxlik$x, y=dens.maxlik$y, type="l", lwd=all.lwd, col=col.seq[4])
abline(v=true, lty=2, lwd=1.5, col="green")
print(mean(history[,2]>true))
llik <- function(b, data, epsilon){
p <- 1/(1 + exp(-b))             	# Transform unconstrained b into 0<p<1
values <- sort(unique(data))        # Transform dichotomous data into z \in {0,1}
z <- rep(0, length(data))
z[data==values[2]] <- 1
ptrue <- exp(epsilon)/(1+exp(epsilon))
pfalse <- 1 - ptrue  # Or 1/(1-exp(epsilon))
# Here's the log likelihood function as a row by row calculation
llik <- z*log(p*ptrue + (1-p)*pfalse) + (1-z)*log((1-p)*ptrue + p*pfalse)
llik <- -1 * sum(llik)  			# Note optim performs minimization
return(llik)
}
myn <- 1000
myepsilon <- 0.5
mydata<-rbinom(n=myn, size=1, prob=0.3)
mydata[mydata==0] <- -1
true <- mean(mydata)
release <- rep(NA, myn)
for(i in 1:myn){
release[i] <- localRelease(x=mydata[i], values=c(-1,1), epsilon=myepsilon)
}
expectation <- correction(release=release, epsilon=myepsilon)
startparams <- -1
output <- nlm(p=startparams, f=llik, data=release, epsilon=myepsilon, stepmax=0.1)
maxlik.p <- 1/(1+exp(-1* output$estimate))
maxlik.mean <- maxlik.p * max(mydata) + (1-maxlik.p) * min(mydata)
cat(paste("Mean of data:       ", mean(mydata), "\n"))
cat(paste("Mean of DP release: ", mean(release), "\n"))
cat(paste("Mean corrected:     ", expectation, "\n"))
cat(paste("MaxLikelihood mean: ", maxlik.mean, "\n"))
p.seq <- seq(from=.01, to=.99, by=.001)     # These are the probabilities we want to find the llikelihood of
b.seq <- -log(p.seq^{-1} - 1)              # These are the inverse transformations
y.lik <- y.llik <- rep(NA, length(p.seq))
for(i in 1:length(p.seq)){
y.llik[i] <- -1*llik(b=b.seq[i], data=release, epsilon=myepsilon)
y.lik[i] <- -1*lik(b=b.seq[i], data=release, epsilon=myepsilon)
}
par(mfcol=c(2,1))
plot(x=p.seq, y=y.llik, type="l", lwd=2, main="LogLikelihood Surface", xlab="Pi Parameter", ylab="LogLikelihood")
plot(x=p.seq, y=y.lik, type="l", lwd=2, main="Likelihood Surface", xlab="Pi Parameter", ylab="Likelihood")
integerHistogramRelease <- function(x, lower, upper, nbins=0, epsilon){
n <- length(x)
if(nbins==0){
lower <- floor(lower)
upper <- ceiling(upper)
bins <- lower:upper
nbins <- length(bins)
}
x.clipped <- clip(x=x, lower=lower, upper=upper)
# sensitivity <- 2
# scale <- sensitivity / epsilon
sensitiveValue <- DPrelease <- rep(NA,nbins)
for(i in 1:length(bins)){
sensitiveValue[i] <- sum(x.clipped==bins[i])
DPrelease[i] <- localRelease(sensitiveValue[i], values=c(0,1), epsilon = epsilon/2)
}
return(list(release=DPrelease, true=sensitiveValue, codebook=bins))
}
nboot <- 2000
data1 <- bootstrap(data, n=nboot)
out1 <- rep(NA, nboot)
for(i in 1:nboot){
out1[i] <- integerHistogramRelease(x=data1[i], lower=1, upper=16, epsilon=0.5)
}
data1 <- bootstrap(data, n=nboot)
stop()
library("foreign")
PUMSdata <- read.csv(file="../../data/FultonPUMS5full.csv")
rm(list=ls())		# Remove any objects in memory
set.seed(123)
localRelease <- function(x, values=c(-1,1), epsilon){
draw <- runif(n=1, min=0, max=1)
cutoff <- 1/(1+exp(epsilon))
if(draw<cutoff){
return(values[!values%in%x])
}else{
return(x)
}
}
correction <- function(release, epsilon){
inflation <- (exp(epsilon) + 1)/(exp(epsilon) - 1)
expectation <- mean(release * inflation)
return(expectation)
}
correction01 <- function(release, epsilon, sensitivity=1){
inflation <- (exp(epsilon/sensitivity) + 1)/(exp(epsilon/sensitivity) - 1)
release.trans <- (release-0.5)*2
expectation <- release.trans * inflation
expectation.trans <- expectation/2 + 0.5
return(expectation.trans)
}
rlap = function(mu=0, b=1, size=1) {
p <- runif(size) - 0.5
draws <- mu - b * sgn(p) * log(1 - 2 * abs(p))
return(draws)
}
sgn <- function(x) {
return(ifelse(x < 0, -1, 1))
}
clip <- function(x, lower, upper){
x.clipped <- x
x.clipped[x.clipped<lower] <- lower
x.clipped[x.clipped>upper] <- upper
return(x.clipped)
}
bootstrap <- function(x, y=NULL, n){
index <- sample(x=1:length(x), size=n, replace=TRUE)
if(is.null(y)){
return(x[index])
}else{
return(list(x=x[index], y=y[index]))
}
}
library("foreign")
PUMSdata <- read.csv(file="../../data/FultonPUMS5full.csv")
getwd()
setwd("~/Desktop/Harvard/S19/cs208/cs208/")
library("foreign")
PUMSdata <- read.csv(file="../../data/FultonPUMS5full.csv")
getwd()
setwd("~/examples/wk7_localmodel")
setwd("~/Desktop/Harvard/S19/cs208/cs208/examples/wk7_localmodel")
PUMSdata <- read.csv(file="../../data/FultonPUMS5full.csv")
data <- PUMSdata$educ    		# variable for means
localHistogramRelease <- function(x, lower, upper, nbins=0, epsilon){
n <- length(x)
if(nbins==0){
lower <- floor(lower)
upper <- ceiling(upper)
bins <- lower:upper
nbins <- length(bins)
}
x.clipped <- clip(x=x, lower=lower, upper=upper)
sensitivity <- 2
scale <- sensitivity / epsilon
sensitiveValue <- DPrelease <- rep(NA,nbins)
for(i in 1:length(bins)){
sensitiveValue[i] <- sum(x.clipped==bins[i])
DPrelease[i] <- localRelease(sensitiveValue[i], values=c(0,1), epsilon=epsilon/2)
}
return(list(release=DPrelease, true=sensitiveValue, codebook=bins))
}
nboot <- 20000
data1 <- bootstrap(data, n=nboot)
truefrac <- function(x, lower, upper){
fractions <- hist(x, breaks=(lower:(upper+1)-0.5), plot=FALSE)$density
return(fractions)
}
out1 <- matrix(NA, nrow=nboot, ncol=16)
for(i in 1:nboot){
out1[i,] <- localHistogramRelease(x=data1[i], lower=1, upper=16, epsilon=0.5)$release
}
out %>% View()
View(out)
View(out1)
values <- apply(out1,2,mean)
sum(out1)
sum(out1)/(nrow(out1)*ncol(out1))
par(mfcol=c(2,1))
barplot(values)
plot(values, type="h", lwd=3)
showHistLocal <- function(DPrelease, true, codebook, main="Histogram"){
semi.blue <- rgb(0,90,239,150,maxColorValue=255)          # Slightly transparent colors
semi.red  <- rgb(239,90,0,150,maxColorValue=255)
allylim <- c(min(c(DPrelease,true), na.rm = TRUE), max(c(DPrelease, true), na.rm = TRUE))
granularity <- (max(codebook) - min(codebook))/(length(codebook)-1)
allxlim <- c(min(codebook) - 0.5*granularity, max(codebook + 0.5*granularity))
# Build empty plot
plot.new()
plot.window( xlim=allxlim, ylim=allylim)
title(main = main)
axis( side=1 )
axis( side=2 )
tiny <- granularity*0.03 # slight spacing between bars
overlap <- granularity*0.2 # some small overlap between sensitive and DP values
for(i in 1:length(codebook)){
rect(xleft=codebook[i]-overlap, ybottom=0, xright=codebook[i]+0.5*granularity-tiny, ytop=true[i], col=semi.red)
rect(xleft=codebook[i]-0.5*granularity+tiny, ybottom=0, xright=codebook[i]+overlap, ytop=DPrelease[i], col=semi.blue)
}
}
values <- apply(out1,2,mean)
DPmeans <- correction01(values, epsilon=0.5)
true <- truefrac(data1, lower=1, upper=16)
par(mfcol=c(1,1))
showHistLocal(DPrelease=DPmeans, true=true, codebook=1:16, main="Histogram of Local Model Release of Education")
dev.copy2pdf(file="./figs/localEducHist.pdf")
values <- apply(out1,2,mean)
DPmeans <- correction01(values, epsilon=0.5, sensitivity=2)
true <- truefrac(data1, lower=1, upper=16)
par(mfcol=c(1,1))
showHistLocal(DPrelease=DPmeans, true=true, codebook=1:16, main="Histogram of Local Model Release of Education")
dev.copy2pdf(file="./figs/localEducHist.pdf")
library("openssl")
sha256(c("james","salil","james"), key="my_secret")
letters
thash <- function(x){
x <- tolower(x)
hash<-NULL
for(i in 1:length(x)){
first.letter <- substr(x[i], start=1, stop=1)
temp <- which(first.letter==letters)
hash <- c(hash, max(temp,0))         # max helps map nonletters to 0
}
return(hash)
}
thash2 <- function(x){
x <- tolower(x)
hash<-NULL
for(i in 1:length(x)){
last.letter <- substr(x[i], start=nchar(x[i]), stop=nchar(x[i]))
temp <- which(last.letter==letters)
hash <- c(hash, max(temp,0))         # max helps map nonletters to 0
}
return(hash)
}
data("iris")
iris
names <- bootstrap(iris$Species, n=5000)
names.hash <- thash(names)
names.hash
names
clientSFP <- function(x, epsilon, myhash){
a <- localHistogramRelease(x=myhash(x), lower=0, upper=26, epsilon=epsilon)
l <- ceiling(runif(1, min=0, max=10))
b <- substr(x, start=l, stop=l)
return(list(a=a, b=b, l=l))
}
x <- bootstrap(iris$Species, n=10000)
l <- rep(1,length(x))
b <- rep("a",length(x))
out4 <- matrix(NA, nrow=length(x), ncol=27)
myepsilon <- 2
for(i in 1:length(x)){
release <- clientSFP(x[i], epsilon=myepsilon, myhash=thash)
out4[i,] <- release$a
b[i] <- release$b
l[i] <- release$l
}
release
release$a
clientSFP <- function(x, epsilon, myhash){
a <- localHistogramRelease(x=myhash(x), lower=0, upper=26, epsilon=epsilon)$release
l <- ceiling(runif(1, min=0, max=10))
b <- substr(x, start=l, stop=l)
return(list(a=a, b=b, l=l))
}
x <- bootstrap(iris$Species, n=10000)
l <- rep(1,length(x))
b <- rep("a",length(x))
out4 <- matrix(NA, nrow=length(x), ncol=27)
myepsilon <- 2
for(i in 1:length(x)){
release <- clientSFP(x[i], epsilon=myepsilon, myhash=thash)
out4[i,] <- release$a
b[i] <- release$b
l[i] <- release$l
}
codebook <- 0:26
values <- apply(out4,2,mean)
DPmeans <- correction01(values, epsilon=myepsilon, sensitivity=2)
true <- truefrac(thash(x), lower=0, upper=26)
showHistLocal(DPrelease=DPmeans, true=true, codebook=0:27, main="Histogram of Local Model Release of Name Hash")
dev.copy2pdf(file="./figs/localHashHist.pdf")
Threshold <- 0.1
discovered <- which(DPmeans>Threshold)
cat("Actual Names: \n")
cat(paste(sort(unique(iris$Species)), "\n"))
for(j in 1:length(discovered)){
flag <- out4[,discovered[j]] == 1
temp.b <- b[flag]
temp.l <- l[flag]
t <- table(temp.b,temp.l)
print(t)
size <- ncol(t)
word <- rep("",size)
for(k in 1:ncol(t)){
word[k]<-row.names(t)[which(t[,k]==max(t[,k]))][1]
}
print(word)
}
x <- bootstrap(iris$Species, n=10000)
l <- rep(1,length(x))
b <- rep("a",length(x))
out4 <- matrix(NA, nrow=length(x), ncol=27)
myepsilon <- 2
for(i in 1:length(x)){
release <- clientSFP(x[i], epsilon=myepsilon, myhash=thash2)
out4[i,] <- release$a
b[i] <- release$b
l[i] <- release$l
}
codebook <- 0:26
values <- apply(out4,2,mean)
DPmeans <- correction01(values, epsilon=myepsilon, sensitivity=2)
true <- truefrac(thash(x), lower=0, upper=26)
showHistLocal(DPrelease=DPmeans, true=true, codebook=0:27, main="Histogram of Local Model Release of Name Hash")
codebook <- 0:26
values <- apply(out4,2,mean)
DPmeans <- correction01(values, epsilon=myepsilon, sensitivity=2)
true <- truefrac(thash2(x), lower=0, upper=26)
showHistLocal(DPrelease=DPmeans, true=true, codebook=0:27, main="Histogram of Local Model Release of Name Hash")
dev.copy2pdf(file="./figs/localHashHist.pdf")
Threshold <- 0.1
discovered <- which(DPmeans>Threshold)
cat("Actual Names: \n")
cat(paste(sort(unique(iris$Species)), "\n"))
for(j in 1:length(discovered)){
flag <- out4[,discovered[j]] == 1
temp.b <- b[flag]
temp.l <- l[flag]
t <- table(temp.b,temp.l)
print(t)
size <- ncol(t)
word <- rep("",size)
for(k in 1:ncol(t)){
word[k]<-row.names(t)[which(t[,k]==max(t[,k]))][1]
}
print(word)
}
library.list <- c("glmnet", "limSolve", "ggplot2", "optparse", "shiny")
install.packages(library.list, repos="https://cran.cnr.berkeley.edu/")
